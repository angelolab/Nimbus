{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673d8e3a",
   "metadata": {},
   "source": [
    "# Nimbus prediction notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f920e689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:30.004569Z",
     "start_time": "2023-09-28T19:09:27.171139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required packages\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from cell_classification.application import Nimbus, prep_deepcell_naming_convention\n",
    "from alpineer import io_utils\n",
    "from ark.utils import example_dataset\n",
    "from cell_classification.viewer_widget import NimbusViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4642fe2",
   "metadata": {},
   "source": [
    "## 0: Set root directory and download example dataset\n",
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder. Set `base_dir`, the path to all of your imaging data (i.e. multiplexed images and segmentation masks). Subdirectory `nimbus_output` will contain all of the data generated by this notebook. In the following, we expect this folder structure:\n",
    "```\n",
    "|-- base_dir\n",
    "|   |-- image_data\n",
    "|   |   |-- fov_1\n",
    "|   |   |-- fov_2\n",
    "|   |-- segmentation\n",
    "|   |   |-- deepcell_output\n",
    "|   |-- nimbus_output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974f8dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:30.008473Z",
     "start_time": "2023-09-28T19:09:30.005361Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = \"../data/example_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade450f",
   "metadata": {},
   "source": [
    "If you would like to test Nimbus with an example dataset, run the cell below. It will download a dataset consisting of 10 FOVs with 22 channels. You may find more information about the example dataset in the [ark-analysis README](https://github.com/angelolab/ark-analysis/blob/bc6685050dfbef4607874fbbadebd4289251c173/README.md#example-dataset). If you want to use your own data, skip the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37733de5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:31.363599Z",
     "start_time": "2023-09-28T19:09:30.008623Z"
    }
   },
   "outputs": [],
   "source": [
    "example_dataset.get_example_dataset(dataset=\"cluster_pixels\", save_dir = base_dir, overwrite_existing = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2ab6c",
   "metadata": {},
   "source": [
    "## 1: set file paths and parameters\n",
    "\n",
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292e4524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:31.367102Z",
     "start_time": "2023-09-28T19:09:31.364755Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
    "deepcell_output_dir = os.path.join(base_dir, \"segmentation\", \"deepcell_output\")\n",
    "nimbus_output_dir = os.path.join(base_dir, \"nimbus_output\")\n",
    "\n",
    "# Create nimbus output directory\n",
    "os.makedirs(nimbus_output_dir, exist_ok=True)\n",
    "\n",
    "# Check if paths exist\n",
    "io_utils.validate_paths([base_dir, tiff_dir, deepcell_output_dir, nimbus_output_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89442a",
   "metadata": {},
   "source": [
    "## 2: Set up input paths and the naming convention for the segmentation data\n",
    "Store names of channels to exclude in the list below. Either predict all FOVs or specify manually the ones you want to apply Nimbus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a319c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:31.370417Z",
     "start_time": "2023-09-28T19:09:31.368471Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the channels to exclude\n",
    "exclude_channels = [\n",
    "    'H3K9ac', 'H3K27me3', \"Au\", \"Fe\", \"Noodle\", \"Ca\", \"CD11c_nuc_exclude\", \"CK17_smoothed\",\n",
    "    \"ECAD_smoothed\", \"FOXP3_nuc_include\",\n",
    "]\n",
    "\n",
    "# either get all fovs in the folder...\n",
    "fov_names = os.listdir(tiff_dir)\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov0\", \"fov1\"]\n",
    "\n",
    "# construct paths for fovs\n",
    "fov_paths = [os.path.join(tiff_dir, fov_name) for fov_name in fov_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c85f682",
   "metadata": {},
   "source": [
    "Define the naming convention for the segmentation data in function `segmentation_naming_convention`, that maps the `fov_name` to the path of the associated segmentation output. The below function `prep_deepcell_naming_convention` assumes that all segmentation outputs are stored in one folder, with the `fov_name` as the prefix and `_whole_cell.tiff` as the suffix, as shown below in the visualization of the folder structure. If this does not apply to your data, you have to define a function `segmentation_naming_convention` that takes an element from `fov_paths` and returns a valid path to the segmentation label map you want to use for that fov.\n",
    "\n",
    "```\n",
    "|-- base_dir\n",
    "|   |-- image_data\n",
    "|   |   |-- fov_1\n",
    "|   |   |-- fov_2\n",
    "|   |-- segmentation\n",
    "|   |   |-- deepcell_output\n",
    "|   |   |   |-- fov_1_whole_cell.tiff\n",
    "|   |   |   |-- fov_2_whole_cell.tiff\n",
    "|   |-- nimbus_output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8256e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:31.373464Z",
     "start_time": "2023-09-28T19:09:31.371859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation data exists for fov 0 and naming convention is correct\n"
     ]
    }
   ],
   "source": [
    "# Prepare segmentation naming convention that maps a fov_path to the according segmentation label map\n",
    "segmentation_naming_convention = prep_deepcell_naming_convention(deepcell_output_dir)\n",
    "\n",
    "# test segmentation_naming_convention\n",
    "if os.path.exists(segmentation_naming_convention(fov_paths[0])):\n",
    "    print(\"Segmentation data exists for fov 0 and naming convention is correct\")\n",
    "else:\n",
    "    print(\"Segmentation data does not exist for fov 0 or naming convention is incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e5240",
   "metadata": {},
   "source": [
    "## 3: Load model and initialize Nimbus application\n",
    "The following code initializes the Nimbus application and loads the model checkpoint. The model was trained on a diverse set of tissues, protein markers, imaging platforms and cell types and doesn't need re-training. If you want to use the model on a machine without GPU, set `test_time_aug=False` to speed up inference. If you run it on a laptop GPU and run into out-of-memory errors, consider reducing the `batch_size` to 1 and the `input_shape` to `[512,512]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd0a575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:23:03.276854Z",
     "start_time": "2023-09-28T19:22:59.098274Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find Nimbus weights at /opt/homebrew/Caskroom/mambaforge/base/envs/Nimbus_macOS/lib/python3.11/checkpoints/halfres_512_checkpoint_160000.h5.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m nimbus \u001B[38;5;241m=\u001B[39m \u001B[43mNimbus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfov_paths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfov_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43msegmentation_naming_convention\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msegmentation_naming_convention\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnimbus_output_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_predictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_time_aug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# check if all inputs are valid\u001B[39;00m\n\u001B[1;32m     13\u001B[0m nimbus\u001B[38;5;241m.\u001B[39mcheck_inputs()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/Nimbus_macOS/lib/python3.11/site-packages/cell_classification/application.py:108\u001B[0m, in \u001B[0;36mNimbus.__init__\u001B[0;34m(self, fov_paths, segmentation_naming_convention, output_dir, save_predictions, exclude_channels, half_resolution, batch_size, test_time_aug, input_shape)\u001B[0m\n\u001B[1;32m    105\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_dir, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    107\u001B[0m \u001B[38;5;66;03m# initialize model and parent class\u001B[39;00m\n\u001B[0;32m--> 108\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28msuper\u001B[39m(Nimbus, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    111\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \n\u001B[1;32m    112\u001B[0m     model_image_shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39minput_shape[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    115\u001B[0m     format_model_output_fn\u001B[38;5;241m=\u001B[39mformat_output,\n\u001B[1;32m    116\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/Nimbus_macOS/lib/python3.11/site-packages/cell_classification/application.py:163\u001B[0m, in \u001B[0;36mNimbus.initialize_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoaded weights from \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheckpoint_path))\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find Nimbus weights at \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\\\n\u001B[1;32m    164\u001B[0m                             \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheckpoint_path))\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Could not find Nimbus weights at /opt/homebrew/Caskroom/mambaforge/base/envs/Nimbus_macOS/lib/python3.11/checkpoints/halfres_512_checkpoint_160000.h5."
     ]
    }
   ],
   "source": [
    "nimbus = Nimbus(\n",
    "    fov_paths=fov_paths,\n",
    "    segmentation_naming_convention=segmentation_naming_convention,\n",
    "    output_dir=nimbus_output_dir,\n",
    "    exclude_channels=exclude_channels,\n",
    "    save_predictions=True,\n",
    "    batch_size=4,\n",
    "    test_time_aug=True,\n",
    "    input_shape=[1024,1024]\n",
    ")\n",
    "\n",
    "# check if all inputs are valid\n",
    "nimbus.check_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce682e",
   "metadata": {},
   "source": [
    "## 4: Prepare normalization dictionary \n",
    "The next step is to iterate through all the fovs and calculate the 0.999 marker expression quantile for each marker individually. This is used for normalizing the marker expressions prior to predicting marker confidence scores with our model. You can set `n_subset` to estimate the quantiles on a small subset of the data and you can set `multiprocessing=True` to speed up computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b100e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T19:09:41.384694Z",
     "start_time": "2023-09-28T19:09:41.382248Z"
    }
   },
   "outputs": [],
   "source": [
    "nimbus.prepare_normalization_dict(\n",
    "    n_subset=50,\n",
    "    multiprocessing=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e782794",
   "metadata": {},
   "source": [
    "## 5: Make predictions with the model\n",
    "Nimbus will iterate through your samples and store predictions and a file named `nimbus_cell_table.csv` that contains the mean-per-cell predicted marker confidence scores in the sub-directory called `nimbus_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76225704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell_table = nimbus.predict_fovs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef2ab9",
   "metadata": {},
   "source": [
    "## 6: View multiplexed channels and Nimbus predictions side-by-side\n",
    "Select an FOV and one marker image per channel to inspect the imaging data and associated Nimbus predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = NimbusViewer(input_dir=tiff_dir, output_dir=nimbus_output_dir)\n",
    "viewer.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
