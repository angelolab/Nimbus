{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f920e689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required packages\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from cell_classification.application import Nimbus\n",
    "from alpineer import io_utils\n",
    "from cell_classification.viewer_widget import NimbusViewer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4642fe2",
   "metadata": {},
   "source": [
    "## 0: Set root directory and download example dataset\n",
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder. Set `base_dir`, the path to all of your imaging data (i.e. multiplexed images and segmentation masks). Subdirectory `nimbus_output` will contain all of the data generated by this notebook. In the following, we expect this folder structure:\n",
    "```\n",
    "|-- base_dir\n",
    "|   |-- image_data\n",
    "|   |   |-- fov_1\n",
    "|   |   |-- fov_2\n",
    "|   |-- segmentation\n",
    "|   |   |-- deepcell_output\n",
    "|   |-- cell_classification\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974f8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = \"E:/angelo_lab/data/TONIC/raw\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cd2ab6c",
   "metadata": {},
   "source": [
    "## 1: set file paths and parameters\n",
    "\n",
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292e4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "tiff_dir = os.path.join(base_dir, \"image_data\", \"samples\")\n",
    "deepcell_output_dir = os.path.join(base_dir, \"segmentation_data\", \"deepcell_output\")\n",
    "nimbus_output_dir = os.path.join(base_dir, \"segmentation_data\", \"nimbus_output\")\n",
    "\n",
    "# Create nimbus output directory\n",
    "os.makedirs(nimbus_output_dir, exist_ok=True)\n",
    "\n",
    "# Check if paths exist\n",
    "io_utils.validate_paths([base_dir, tiff_dir, deepcell_output_dir, nimbus_output_dir])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae89442a",
   "metadata": {},
   "source": [
    "## 2: Set up input paths and the naming convention for the segmentation data\n",
    "Store names of channels to exclude in the list below. Either predict all FOVs or specify manually the ones you want to apply nimbus on. The `segmentation_naming_convention` maps a FOV path to the according instance segmentation output path. Please make sure, that `segmentation_naming_convention` returns the path to the correct cell segmentation output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8256e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation data exists for fov 0 and naming convention is correct\n"
     ]
    }
   ],
   "source": [
    "# define the channels to exclude\n",
    "exclude_channels = [\n",
    "    'H3K9ac', 'H3K27me3', \"Au\", \"Fe\", \"Noodle\", \"Ca\", \"CD11c_nuc_exclude\", \"CK17_smoothed\",\n",
    "    \"Collagen1\", \"ECAD_smoothed\", \"FOXP3_nuc_include\", \"SMA\", \"VIM\"\n",
    "]\n",
    "\n",
    "# either get all fovs in the folder...\n",
    "fov_names = os.listdir(tiff_dir)\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov0\", \"fov1\"]\n",
    "\n",
    "fov_paths = [os.path.join(tiff_dir, fov_name) for fov_name in fov_names]\n",
    "\n",
    "# define the naming convention for the segmentation data\n",
    "def segmentation_naming_convention(fov_path):\n",
    "    \"\"\"Prepares the path to the segmentation data for a given fov\n",
    "    Args:\n",
    "        fov_path (str): path to fov\n",
    "    Returns:\n",
    "        seg_path (str): paths to segmentation fovs\n",
    "    \"\"\"\n",
    "    fov_name = os.path.basename(fov_path)\n",
    "    return os.path.join(\n",
    "        deepcell_output_dir, fov_name + \"_feature_0.tif\"\n",
    "    )\n",
    "\n",
    "# test segmentation naming convention\n",
    "if os.path.exists(segmentation_naming_convention(fov_paths[0])):\n",
    "    print(\"Segmentation data exists for fov 0 and naming convention is correct\")\n",
    "else:\n",
    "    print(\"Segmentation data does not exist for fov 0 or naming convention is incorrect\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "839e5240",
   "metadata": {},
   "source": [
    "## 3: Load model and initialize Nimbus application\n",
    "The following code initializes the Nimbus application and loads the model checkpoint. The model was trained on a diverse set of tissues, protein markers, imaging platforms and cell types and doesn't need re-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd0a575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from E:\\angelo_lab\\cell_classification\\checkpoints\\halfres_512_checkpoint_160000.h5\n",
      "All inputs are valid.\n"
     ]
    }
   ],
   "source": [
    "nimbus = Nimbus(\n",
    "    fov_paths=fov_paths,\n",
    "    segmentation_naming_convention=segmentation_naming_convention,\n",
    "    output_dir=nimbus_output_dir,\n",
    "    exclude_channels=exclude_channels,\n",
    "    save_predictions=True,\n",
    ")\n",
    "\n",
    "# check if all inputs are valid\n",
    "nimbus.check_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce682e",
   "metadata": {},
   "source": [
    "## 4: Prepare normalization dictionary \n",
    "The next step is to iterate through all the fovs and calculate the 0.999 marker expression quantile for each marker individually. This is used for normalizing the marker expressions prior to predicting marker confidence scores with our model. You can set `n_subset` to estimate the quantiles on a small subset of the data and you can set `multiprocessing` to speed up computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b100e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate over fovs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76281eb8a26f426cae4ac22b963bcd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nimbus.prepare_normalization_dict(\n",
    "    n_subset=5,\n",
    "    multiprocessing=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e782794",
   "metadata": {},
   "source": [
    "## 5: Make predictions with the model\n",
    "Nimbus will iterate through your samples and store predictions and a file named `nimbus_cell_table.csv` that contains the mean-per-cell predicted marker confidence scores in the sub-directory called `nimbus_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76225704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Predictions will be saved in E:/angelo_lab/data/TONIC/raw\\segmentation_data\\nimbus_output\n",
      "Iterating through fovs will take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a060ee9f1ac4ab999d09bf0dc49ff79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cell_table = nimbus.predict_fovs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef2ab9",
   "metadata": {},
   "source": [
    "## 6: View multiplexed channels and Nimbus predictions side-by-side\n",
    "Select an FOV and one marker image per channel to inspect the imaging data and associated Nimbus predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4b91c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from io import BytesIO\n",
    "from skimage import io\n",
    "from copy import copy\n",
    "\n",
    "class NimbusViewer(object):\n",
    "    def __init__(self, input_dir, output_dir, img_width='600px'):\n",
    "        \"\"\"Viewer for Nimbus application.\n",
    "        Args:\n",
    "            input_dir (str): Path to directory containing individual channels of multiplexed images.\n",
    "            output_dir (str): Path to directory containing output of Nimbus application.\n",
    "            img_width (str): Width of images in viewer.\n",
    "        \"\"\"\n",
    "        self.image_width = img_width\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.fov_names = [os.path.basename(p) for p in os.listdir(output_dir) if os.path.isdir(os.path.join(output_dir, p))]\n",
    "        self.update_button = widgets.Button(description=\"Update Image\")\n",
    "        self.update_button.on_click(self.update_button_click)\n",
    "\n",
    "        self.fov_select = widgets.Select(\n",
    "            options=self.fov_names,\n",
    "            description='FOV:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.fov_select.observe(self.select_fov, names='value')\n",
    "\n",
    "        self.red_select = widgets.Select(\n",
    "            options=[],\n",
    "            description='Red:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.green_select = widgets.Select(\n",
    "            options=[],\n",
    "            description='Green:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.blue_select = widgets.Select(\n",
    "            options=[],\n",
    "            description='Blue:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.input_image = widgets.Image()\n",
    "        self.output_image = widgets.Image()\n",
    "\n",
    "    def select_fov(self, change):\n",
    "        fov_path = os.path.join(self.output_dir, self.fov_select.value)\n",
    "        channels = [ch for ch in os.listdir(fov_path) if os.path.isfile(os.path.join(fov_path, ch))]\n",
    "        self.red_select.options = channels\n",
    "        self.green_select.options = channels\n",
    "        self.blue_select.options = channels\n",
    "\n",
    "    def create_composite_image(self, path_dict):\n",
    "        output_image = []\n",
    "        img = None\n",
    "        for k, p in path_dict.items():\n",
    "            if p:\n",
    "                img = io.imread(p)\n",
    "                output_image.append(img)\n",
    "            if p is None:\n",
    "                non_none = [p for p in path_dict.values() if p]\n",
    "                if not img:\n",
    "                    img = io.imread(non_none[0])\n",
    "                output_image.append(img*0)\n",
    "\n",
    "        composite_image = np.stack(output_image, axis=-1)\n",
    "        return composite_image\n",
    "\n",
    "    def layout(self):\n",
    "        channel_selectors = widgets.VBox([\n",
    "            self.red_select,\n",
    "            self.green_select,\n",
    "            self.blue_select\n",
    "        ])\n",
    "        self.input_image.layout.width = self.image_width\n",
    "        self.output_image.layout.width = self.image_width\n",
    "        viewer_html = widgets.HTML(\"<h2>Select files</h2>\")\n",
    "        input_html = widgets.HTML(\"<h2>Input</h2>\")\n",
    "        output_html = widgets.HTML(\"<h2>Nimbus Output</h2>\")\n",
    "\n",
    "        layout = widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                viewer_html,\n",
    "                self.fov_select,\n",
    "                channel_selectors,\n",
    "                self.update_button\n",
    "            ]),\n",
    "        widgets.VBox([\n",
    "            input_html,\n",
    "            self.input_image\n",
    "        ]),\n",
    "        widgets.VBox([\n",
    "            output_html,\n",
    "            self.output_image\n",
    "        ])\n",
    "        ])\n",
    "        display(layout)\n",
    "\n",
    "    def search_for_similar(self, select_value):\n",
    "        in_f_path = os.path.join(self.input_dir, self.fov_select.value)\n",
    "        # search for similar filename in in_f_path\n",
    "        in_f_files = [f for f in os.listdir(in_f_path) if os.path.isfile(os.path.join(in_f_path, f))]\n",
    "        similar_path = None\n",
    "        for f in in_f_files:\n",
    "            if select_value.split(\".\")[0]+\".\" in f:\n",
    "                similar_path = os.path.join(self.input_dir, self.fov_select.value, f)\n",
    "        return similar_path\n",
    "\n",
    "    def update_img(self, image_viewer, composite_image):\n",
    "        # Convert composite image to bytes and assign it to the output_image widget\n",
    "        with BytesIO() as output_buffer:\n",
    "            io.imsave(output_buffer, composite_image, format=\"png\")  # Save as PNG (you can change the format)\n",
    "            output_buffer.seek(0)\n",
    "            image_viewer.value = output_buffer.read()\n",
    "\n",
    "    def update_composite(self):\n",
    "        path_dict = {\n",
    "            \"red\": None,\n",
    "            \"green\": None,\n",
    "            \"blue\": None\n",
    "        }\n",
    "        in_path_dict = copy(path_dict)\n",
    "        if self.red_select.value:\n",
    "            path_dict[\"red\"] = os.path.join(self.output_dir, self.fov_select.value, self.red_select.value)\n",
    "            in_path_dict[\"red\"] = self.search_for_similar(self.red_select.value)\n",
    "        if self.green_select.value:\n",
    "            path_dict[\"green\"] = os.path.join(self.output_dir, self.fov_select.value, self.green_select.value)\n",
    "            in_path_dict[\"green\"] = self.search_for_similar(self.green_select.value)\n",
    "        if self.blue_select.value:\n",
    "            path_dict[\"blue\"] = os.path.join(self.output_dir, self.fov_select.value, self.blue_select.value)\n",
    "            in_path_dict[\"blue\"] = self.search_for_similar(self.blue_select.value)\n",
    "        non_none = [p for p in path_dict.values() if p]\n",
    "        if not non_none:\n",
    "            return\n",
    "        composite_image = self.create_composite_image(path_dict)\n",
    "        in_composite_image = self.create_composite_image(in_path_dict)\n",
    "        in_composite_image = in_composite_image / np.quantile(in_composite_image, 0.999, axis=(0,1))\n",
    "        in_composite_image = np.clip(in_composite_image*255, 0, 255).astype(np.uint8)\n",
    "        # update image viewers\n",
    "        self.update_img(self.input_image, in_composite_image)\n",
    "        self.update_img(self.output_image, composite_image)\n",
    "\n",
    "    def update_button_click(self, button):\n",
    "        self.update_composite()\n",
    "    \n",
    "    def display(self):\n",
    "        self.select_fov(None)\n",
    "        self.layout()\n",
    "        self.update_composite() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f95e351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2f282467604e1abd22cd872f212bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h2>Select files</h2>'), Select(description='FOV:', options=('TONIC_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "select_fov() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:707\u001b[0m, in \u001b[0;36mWidget._handle_msg\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mbuffer_paths\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m data:\n\u001b[0;32m    706\u001b[0m             _put_buffers(state, data[\u001b[39m'\u001b[39m\u001b[39mbuffer_paths\u001b[39m\u001b[39m'\u001b[39m], msg[\u001b[39m'\u001b[39m\u001b[39mbuffers\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 707\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_state(state)\n\u001b[0;32m    709\u001b[0m \u001b[39m# Handle a state request.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrequest_state\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:589\u001b[0m, in \u001b[0;36mWidget.set_state\u001b[1;34m(self, sync_data)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys:\n\u001b[0;32m    587\u001b[0m     from_json \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrait_metadata(name, \u001b[39m'\u001b[39m\u001b[39mfrom_json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    588\u001b[0m                                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trait_from_json)\n\u001b[1;32m--> 589\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_trait(name, from_json(sync_data[name], \u001b[39mself\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:1502\u001b[0m, in \u001b[0;36mHasTraits.hold_trait_notifications\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1500\u001b[0m \u001b[39mfor\u001b[39;00m changes \u001b[39min\u001b[39;00m cache\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m   1501\u001b[0m     \u001b[39mfor\u001b[39;00m change \u001b[39min\u001b[39;00m changes:\n\u001b[1;32m-> 1502\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnotify_change(change)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:635\u001b[0m, in \u001b[0;36mWidget.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_send_property(name, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name)):\n\u001b[0;32m    633\u001b[0m         \u001b[39m# Send new state to front-end\u001b[39;00m\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_state(key\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 635\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mnotify_change(change)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:1517\u001b[0m, in \u001b[0;36mHasTraits.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnotify_change\u001b[39m(\u001b[39mself\u001b[39m, change):\n\u001b[0;32m   1516\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Notify observers of a change event\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_notify_observers(change)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:1564\u001b[0m, in \u001b[0;36mHasTraits._notify_observers\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(c, EventHandler) \u001b[39mand\u001b[39;00m c\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1562\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, c\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1564\u001b[0m c(event)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\ipywidgets\\widgets\\widget_selection.py:233\u001b[0m, in \u001b[0;36m_Selection._propagate_index\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m label\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value:\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue \u001b[39m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:732\u001b[0m, in \u001b[0;36mTraitType.__set__\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[39mraise\u001b[39;00m TraitError(\u001b[39m'\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m trait is read-only.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[0;32m    731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset(obj, value)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:721\u001b[0m, in \u001b[0;36mTraitType.set\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    717\u001b[0m     silent \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[39mif\u001b[39;00m silent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[39m# we explicitly compare silent to True just in case the equality\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[39m# comparison above returns something other than True/False\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     obj\u001b[39m.\u001b[39;49m_notify_trait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, old_value, new_value)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:1505\u001b[0m, in \u001b[0;36mHasTraits._notify_trait\u001b[1;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_notify_trait\u001b[39m(\u001b[39mself\u001b[39m, name, old_value, new_value):\n\u001b[1;32m-> 1505\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnotify_change(\n\u001b[0;32m   1506\u001b[0m         Bunch(\n\u001b[0;32m   1507\u001b[0m             name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1508\u001b[0m             old\u001b[39m=\u001b[39;49mold_value,\n\u001b[0;32m   1509\u001b[0m             new\u001b[39m=\u001b[39;49mnew_value,\n\u001b[0;32m   1510\u001b[0m             owner\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1511\u001b[0m             \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mchange\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1512\u001b[0m         )\n\u001b[0;32m   1513\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\ipywidgets\\widgets\\widget.py:635\u001b[0m, in \u001b[0;36mWidget.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_send_property(name, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name)):\n\u001b[0;32m    633\u001b[0m         \u001b[39m# Send new state to front-end\u001b[39;00m\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_state(key\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 635\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mnotify_change(change)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:1517\u001b[0m, in \u001b[0;36mHasTraits.notify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnotify_change\u001b[39m(\u001b[39mself\u001b[39m, change):\n\u001b[0;32m   1516\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Notify observers of a change event\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_notify_observers(change)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepcell\\lib\\site-packages\\traitlets\\traitlets.py:1564\u001b[0m, in \u001b[0;36mHasTraits._notify_observers\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(c, EventHandler) \u001b[39mand\u001b[39;00m c\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1562\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, c\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1564\u001b[0m c(event)\n",
      "\u001b[1;31mTypeError\u001b[0m: select_fov() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "viewer = NimbusViewer(input_dir=tiff_dir, output_dir=nimbus_output_dir)\n",
    "viewer.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
