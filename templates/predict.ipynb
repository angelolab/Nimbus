{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f920e689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\angelo_lab\\cell_classification\\src\\cell_classification\\inference.py:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tifffile import imwrite\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from cell_classification.inference import prepare_normalization_dict, predict\n",
    "from cell_classification.application import CellClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1042e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from alpineer import io_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4642fe2",
   "metadata": {},
   "source": [
    "## 0: Set root directory and download example dataset\n",
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder. Set `base_dir`, the path to all of your imaging data (i.e. multiplexed images and segmentation masks). Subdirectory `cell_classification` will contain all of the data generated by this notebook. In the following, we expect this folder structure:\n",
    "```\n",
    "|-- base_dir\n",
    "|   |-- image_data\n",
    "|   |   |-- fov_1\n",
    "|   |   |-- fov_2\n",
    "|   |-- segmentation\n",
    "|   |   |-- deepcell_output\n",
    "|   |-- cell_classification\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974f8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = \"E:/angelo_lab/data/TONIC/raw\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cd2ab6c",
   "metadata": {},
   "source": [
    "## 1: set file paths and parameters\n",
    "\n",
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n",
    "\n",
    "If you're interested in directly interfacing with Google Drive, consult the documentation [here](https://ark-analysis.readthedocs.io/en/latest/_rtd/google_docs_usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292e4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "tiff_dir = os.path.join(base_dir, \"image_data/samples\")\n",
    "deepcell_output_dir = os.path.join(base_dir, \"segmentation_data/deepcell_output\")\n",
    "nimbus_output_dir = os.path.join(base_dir, \"segmentation_data/nimbus_output\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae89442a",
   "metadata": {},
   "source": [
    "## 2: Load data and prepare normalization dictionary\n",
    "The next step is to iterate through all the fovs and calculate the 0.999 marker expression quantile for each marker individually. This is used for normalizing the marker expressions prior to predicting marker positivity/negativity with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8256e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate over fovs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e96daca45c4c959cc4c26c7f0b36f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make output directory\n",
    "os.makedirs(nimbus_output_dir, exist_ok=True)\n",
    "\n",
    "# define the channels to exclude\n",
    "exclude_channels = ['H3K9ac', 'H3K27me3', \"Au\", \"Fe\", \"Noodle\", \"Ca\"]\n",
    "\n",
    "# either get all fovs in the folder...\n",
    "fov_names = os.listdir(tiff_dir)\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov0\", \"fov1\"]\n",
    "\n",
    "fov_paths = [os.path.join(tiff_dir, fov_name) for fov_name in fov_names]\n",
    "\n",
    "# Prepare or load training data normalization dict\n",
    "normalization_dict = prepare_normalization_dict(\n",
    "    fov_paths,\n",
    "    output_dir=nimbus_output_dir,\n",
    "    exclude_channels=exclude_channels,\n",
    "    n_jobs=16)\n",
    "# normalization_dict = json.load(open(os.path.join(cell_classification_output_dir, 'normalization_dict.json')))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "839e5240",
   "metadata": {},
   "source": [
    "## 3: Load model and initialize deepcell application\n",
    "The following code initializes the deepcell application and loads the model checkpoint. The checkpoint needs to be downloaded from [here](https://charitede-my.sharepoint.com/:u:/g/personal/josef-lorenz_rumberger_charite_de/Ed5iVEMreE5DqJ_WczdXS9EBFeD75ZmaLdYWXENvUvUbSg?e=r2hxK8) and put under path `checkpoints/checkpoint_125000.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f312a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from ..\\checkpoints\\halfres_512_checkpoint_160000.h5\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "checkpoint_path = os.path.normpath(\"../checkpoints/halfres_512_checkpoint_160000.h5\")\n",
    "\n",
    "\n",
    "# change this function to match your segmentation naming convention\n",
    "def segmentation_naming_convention(fov_path):\n",
    "    \"\"\"Prepares the path to the segmentation data for a given fov\n",
    "    Args:\n",
    "        fov_path (str): path to fov\n",
    "    Returns:\n",
    "        seg_path (str): paths to segmentation fovs\n",
    "    \"\"\"\n",
    "    fov_name = os.path.basename(fov_path)\n",
    "    return os.path.join(\n",
    "        deepcell_output_dir, fov_name + \"_feature_0.tif\"\n",
    "    )\n",
    "\n",
    "\n",
    "app = CellClassification()\n",
    "app.load_weights(checkpoint_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e782794",
   "metadata": {},
   "source": [
    "## 4: Make predictions with the model\n",
    "Determine if you want to (a) plot the predictions, (b) save the prediction images and (c) use test-time augmentation during inference. The script will iterate through your samples and store predictions and a file named `pred_cell_table.csv` that contains the mean-per-cell predicted marker activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76225704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m test_time_aug \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m half_resolution \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m cell_table \u001b[39m=\u001b[39m predict(\n\u001b[0;32m      9\u001b[0m             fov_paths,\n\u001b[0;32m     10\u001b[0m             nimbus_output_dir,\n\u001b[0;32m     11\u001b[0m             app,\n\u001b[0;32m     12\u001b[0m             normalization_dict,\n\u001b[0;32m     13\u001b[0m             segmentation_naming_convention,\n\u001b[0;32m     14\u001b[0m             exclude_channels\u001b[39m=\u001b[39;49mexclude_channels,\n\u001b[0;32m     15\u001b[0m             plot_predictions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     16\u001b[0m             save_predictions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     17\u001b[0m             half_resolution\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     18\u001b[0m             )\n",
      "Cell \u001b[1;32mIn[9], line 67\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(fov_paths, cell_classification_output_dir, app, normalization_dict, segmentation_naming_convention, exclude_channels, plot_predictions, save_predictions, half_resolution)\u001b[0m\n\u001b[0;32m     65\u001b[0m instance_path \u001b[39m=\u001b[39m segmentation_naming_convention(fov_path)\n\u001b[0;32m     66\u001b[0m instance_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(io\u001b[39m.\u001b[39mimread(instance_path))\n\u001b[1;32m---> 67\u001b[0m input_data \u001b[39m=\u001b[39m prepare_input_data(mplex_img, instance_mask)\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m half_resolution:\n\u001b[0;32m     69\u001b[0m     scale \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_input_data' is not defined"
     ]
    }
   ],
   "source": [
    "# plot and save images\n",
    "\n",
    "plot_predictions = False\n",
    "save_predictions = True\n",
    "test_time_aug = True\n",
    "half_resolution = True\n",
    "\n",
    "cell_table = predict(\n",
    "            fov_paths,\n",
    "            nimbus_output_dir,\n",
    "            app,\n",
    "            normalization_dict,\n",
    "            segmentation_naming_convention,\n",
    "            exclude_channels=exclude_channels,\n",
    "            plot_predictions=True,\n",
    "            save_predictions=True,\n",
    "            half_resolution=False,\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
